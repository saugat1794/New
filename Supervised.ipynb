{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1sw1CtBmag0GI4mTuaAYX2HtxAOZzme7C",
      "authorship_tag": "ABX9TyN1RsRmWi/4QuBauNHqtMvx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saugat1794/New/blob/master/Supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HXLWfAuul4U-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from natsort import natsorted"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "%cd gdrive/MyDrive/Data_For_Final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2kI9a1qm5kQ",
        "outputId": "3a11dbfc-1d07-447e-9321-8a3cdaa7f2a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/MyDrive/Data_For_Final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_UxryOiip62g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing text**"
      ],
      "metadata": {
        "id": "-SMEn-X_3BwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import nltk \n",
        "from nltk import sent_tokenize # this helps to split text into Sentences\n",
        "from nltk import word_tokenize # this helps to split text into individual Words\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slFNM3Zv27tM",
        "outputId": "97211652-cf08-49a2-eda4-41832dccc70e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function for preprocessing text\n",
        "def preprocess(text):\n",
        "    # Tokenize the text into sentences and words\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "    # Remove stop words and punctuations\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [[word for word in sentence if word.isalnum() and word not in stop_words] for sentence in words]\n",
        "\n",
        "    # Lemmatize the words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [[lemmatizer.lemmatize(word) for word in sentence] for sentence in words]\n",
        "\n",
        "    # Combine the words back into sentences\n",
        "    sentences = [' '.join(sentence) for sentence in words]\n",
        "    return ' '.join(sentences)"
      ],
      "metadata": {
        "id": "6jMHejHU3Ggu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##importing packages necessary for summarization\n",
        "import sumy\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer"
      ],
      "metadata": {
        "id": "k5DXzNLT3M9o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for cleaning data\n",
        "import re\n",
        "def clean_data(data):\n",
        "  text = re.sub(r\"\\[[0-9]*\\]\",\" \",data)\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'\\s+',\" \",text)\n",
        "  text = re.sub(r\",\",\" \",text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "rwHfU0tH3e4k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for text summarization\n",
        "def summarize(cleaned_article_content, num_of_sentence):\n",
        "  cleaned_article_content = clean_data(cleaned_article_content)\n",
        "  cleaned_article_content = preprocess(cleaned_article_content)\n",
        "  summarized_text =''\n",
        "  parser = PlaintextParser.from_string(cleaned_article_content,Tokenizer(\"english\"))\n",
        "  summarizer = LexRankSummarizer()\n",
        "  summary = summarizer(parser.document, num_of_sentence)\n",
        "  for sentence in summary:\n",
        "    summarized_text = summarized_text + str(sentence)\n",
        "    return summarized_text"
      ],
      "metadata": {
        "id": "xPQsU28u3hXa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get_Resume**"
      ],
      "metadata": {
        "id": "U2UGCMT93oP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def return_resume():\n",
        "    resumes = []\n",
        "    file_list = os.listdir()\n",
        "    sorted_files_list = natsorted(file_list)\n",
        "    for sorted_files in sorted_files_list:\n",
        "        for file in os.listdir():\n",
        "            if file == sorted_files:\n",
        "                files = open(file, 'r')\n",
        "                resume = summarize(files.read(), 40)\n",
        "                resumes.append(resume)\n",
        "    return resumes\n",
        "\n",
        "def get_job_description():\n",
        "    file_list = os.listdir()\n",
        "    for file in os.listdir():\n",
        "        if file.endswith('txt'):\n",
        "            job_desc = open(file, 'r')\n",
        "            job_desc_text = summarize(job_desc.read(), 40)\n",
        "    return job_desc_text"
      ],
      "metadata": {
        "id": "9Q-PmU2p3rL0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ENCODING WITH BERT**"
      ],
      "metadata": {
        "id": "Ykok9sqz4-kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spJck3GM5ZuF",
        "outputId": "c06c76cb-bfc9-4376-bd1e-62329879ddf0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chief Financial Officer** *italicised text*"
      ],
      "metadata": {
        "id": "y4MSw4QDpwjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Chief_Financial_Officer/candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUfVxyubovCc",
        "outputId": "1e7d04eb-d496-4ae7-b5db-cc1e1d80d767"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final/Chief_Financial_Officer/candidates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_CFO = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iklsNatmCrj",
        "outputId": "d408d395-b96e-428a-96a1-daae2b1d99f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final/Chief_Financial_Officer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business_Intelligence_Analyst**"
      ],
      "metadata": {
        "id": "fE7BpQHUCZRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd Business_Intelligence_Analyst/candidates\n",
        "\n",
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_BI_Analyst = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLK55RUH9GZE",
        "outputId": "2c381c0e-6fda-4ea0-91ae-8e995ee863b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final\n",
            "/content/gdrive/MyDrive/Data_For_Final/Business_Intelligence_Analyst/candidates\n",
            "/content/gdrive/MyDrive/Data_For_Final/Business_Intelligence_Analyst\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Financial_Controller**\n",
        "\n"
      ],
      "metadata": {
        "id": "ZEpVcEUz93Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd Financial_Controller/candidates\n",
        "\n",
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_Financial_Controller = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aXblVdjDvCl",
        "outputId": "14957f67-006a-4b0e-dfdf-c07393743df0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final\n",
            "/content/gdrive/MyDrive/Data_For_Final/Financial_Controller/candidates\n",
            "/content/gdrive/MyDrive/Data_For_Final/Financial_Controller\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Marketing_Manager**"
      ],
      "metadata": {
        "id": "UpvW3_XjD5HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd Marketing_Manager/candidates\n",
        "\n",
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_Marketing_Manager = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8sVQUn1D837",
        "outputId": "637b1018-a997-42ae-e2a7-35172e315ffb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final\n",
            "/content/gdrive/MyDrive/Data_For_Final/Marketing_Manager/candidates\n",
            "/content/gdrive/MyDrive/Data_For_Final/Marketing_Manager\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Operation Manager**"
      ],
      "metadata": {
        "id": "W79abkPWEGSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd Operation_Manager/candidates\n",
        "\n",
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_Operation_Manager = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lirXaesEREs",
        "outputId": "ffb59397-21bb-4c9b-8737-0d5106386e8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final\n",
            "/content/gdrive/MyDrive/Data_For_Final/Operation_Manager/candidates\n",
            "/content/gdrive/MyDrive/Data_For_Final/Operation_Manager\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Senior_Accountant**"
      ],
      "metadata": {
        "id": "HVho2NFVEYqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd Senior_Accountant/candidates\n",
        "\n",
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_Senior_Accountant = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtQraIr0EgNW",
        "outputId": "b3253473-561c-44da-cb1d-9422dd44d896"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final\n",
            "/content/gdrive/MyDrive/Data_For_Final/Senior_Accountant/candidates\n",
            "/content/gdrive/MyDrive/Data_For_Final/Senior_Accountant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Senior_Cost_Accountant**"
      ],
      "metadata": {
        "id": "sWPMvZMwEo1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd Senior_Cost_Accountant/candidates\n",
        "\n",
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_Senior_Cost_Accountant = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOtCMWwvEsu7",
        "outputId": "fb0fdea5-1944-4a43-d2c9-db827873061d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final\n",
            "/content/gdrive/MyDrive/Data_For_Final/Senior_Cost_Accountant/candidates\n",
            "/content/gdrive/MyDrive/Data_For_Final/Senior_Cost_Accountant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vice_President_of_Finance**"
      ],
      "metadata": {
        "id": "ThnfOLvaE4E3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd Vice_President_of_Finance/candidates\n",
        "\n",
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_Vice_President_of_Finance = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU6NWryCE85Y",
        "outputId": "6b53cf06-5c4f-4bab-a507-0f84487e435b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final\n",
            "/content/gdrive/MyDrive/Data_For_Final/Vice_President_of_Finance/candidates\n",
            "/content/gdrive/MyDrive/Data_For_Final/Vice_President_of_Finance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VP_Controller**"
      ],
      "metadata": {
        "id": "m0PHDH4fFFlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd VP_Controller/candidates\n",
        "\n",
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_VP_Controller = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h4aONx9FJM0",
        "outputId": "c1b8e4b5-f1e6-4047-d3d3-ec4e07010b9a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final\n",
            "/content/gdrive/MyDrive/Data_For_Final/VP_Controller/candidates\n",
            "/content/gdrive/MyDrive/Data_For_Final/VP_Controller\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VP_Marketing**"
      ],
      "metadata": {
        "id": "EFZ42uiKFQ6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd VP_Marketing/candidates\n",
        "\n",
        "import pandas as pd\n",
        "resumes = return_resume()\n",
        "targets = list(range(1, len(resumes)+1))\n",
        "percentages = []\n",
        "\n",
        "for rank in targets:\n",
        "  percentage = round(((len(resumes) - rank + 1)/ len(resumes)), 2)\n",
        "  percentages.append(percentage)\n",
        "\n",
        "%cd ..\n",
        "job_desc = get_job_description()\n",
        "\n",
        "df_VP_Marketing = pd.DataFrame({'resume': resumes, 'job_description': [job_desc] * len(resumes), 'rank': percentages})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz_1VTF1FUQy",
        "outputId": "9a6a4bcf-d62b-451f-fa99-0146e7b72188"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Data_For_Final\n",
            "/content/gdrive/MyDrive/Data_For_Final/VP_Marketing/candidates\n",
            "/content/gdrive/MyDrive/Data_For_Final/VP_Marketing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([df_CFO, df_BI_Analyst, df_Financial_Controller, df_Marketing_Manager, df_Operation_Manager, df_Senior_Accountant, df_Senior_Cost_Accountant, df_Vice_President_of_Finance, df_VP_Controller, df_VP_Marketing], ignore_index = True)"
      ],
      "metadata": {
        "id": "hD9i6gHJFdWN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import pandas as pd\n",
        "\n",
        "# Define a function to embed a piece of text using BERT\n",
        "def embed_text(text):\n",
        "    # Tokenize the text and get the attention mask\n",
        "    encoded_dict = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512,\n",
        "                                          padding='max_length', truncation=True, return_attention_mask=True,\n",
        "                                          return_tensors='pt')\n",
        "    input_ids = encoded_dict['input_ids']\n",
        "    attention_mask = encoded_dict['attention_mask']\n",
        "    # Feed the input and attention mask to the model to obtain the embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    # Extract the embeddings from the last layer of the model\n",
        "    embeddings = outputs[0].detach().numpy()[0]\n",
        "    return embeddings  \n",
        "\n",
        "\n",
        "df_new = pd.DataFrame(columns = ['Resume_embedding', 'job_desc_embedding', 'target'])\n",
        "df_new['Resume_embedding'] = final_df['resume'].apply(embed_text)\n",
        "df_new['job_desc_embedding'] = final_df['job_description'].apply(embed_text)\n",
        "df_new['target'] = final_df['rank']"
      ],
      "metadata": {
        "id": "eb4ANt5lIAPp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.to_csv('/content/gdrive/MyDrive/save_local.csv', index = False)"
      ],
      "metadata": {
        "id": "lRr9ijPeLcUa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWxTRG0rOzjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dividing into train test**"
      ],
      "metadata": {
        "id": "Kohzfx_NO6_q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "il_uMOz4O_xK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}